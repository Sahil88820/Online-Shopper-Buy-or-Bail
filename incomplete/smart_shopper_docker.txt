# ============================================================
# Dockerfile for Smart Shopper AI Backend (FastAPI)
# ============================================================

FROM python:3.9-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create necessary directories
RUN mkdir -p models data/processed outputs

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Run FastAPI application
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]


# ============================================================
# Dockerfile for Streamlit Dashboard
# ============================================================
# Save as: Dockerfile.streamlit

FROM python:3.9-slim

WORKDIR /app

# Install dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

COPY requirements-streamlit.txt .
RUN pip install --no-cache-dir -r requirements-streamlit.txt

# Copy application
COPY streamlit_app.py .

# Expose Streamlit port
EXPOSE 8501

# Run Streamlit
CMD ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]


# ============================================================
# docker-compose.yml - Multi-container setup
# ============================================================
# Save as: docker-compose.yml

version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:14-alpine
    container_name: smart_shopper_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-smart_shopper_ai}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - smart_shopper_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: smart_shopper_api
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-smart_shopper_ai}
      API_ENV: production
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./outputs:/app/outputs
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - smart_shopper_network
    restart: unless-stopped

  # Streamlit Dashboard
  streamlit:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    container_name: smart_shopper_dashboard
    environment:
      API_URL: http://api:8000
    ports:
      - "8501:8501"
    depends_on:
      - api
    networks:
      - smart_shopper_network
    restart: unless-stopped

volumes:
  postgres_data:

networks:
  smart_shopper_network:
    driver: bridge


# ============================================================
# .dockerignore
# ============================================================
# Save as: .dockerignore

__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
.pytest_cache/
.coverage
htmlcov/
.tox/
.env
.venv
*.log
.git
.gitignore
README.md
*.md
notebooks/
tests/
.DS_Store
.vscode/
.idea/


# ============================================================
# requirements.txt - Python dependencies
# ============================================================
# Save as: requirements.txt

# Core ML libraries
scikit-learn==1.3.0
pandas==2.1.0
numpy==1.24.3

# Gradient boosting
catboost==1.2
xgboost==2.0.0

# Model explainability
shap==0.42.1

# API framework
fastapi==0.103.1
uvicorn[standard]==0.23.2
pydantic==2.3.0

# Database
sqlalchemy==2.0.20
psycopg2-binary==2.9.7

# Utilities
python-multipart==0.0.6
python-dotenv==1.0.0
joblib==1.3.2
requests==2.31.0

# Visualization (for model training)
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.16.1


# ============================================================
# requirements-streamlit.txt - Streamlit dependencies
# ============================================================
# Save as: requirements-streamlit.txt

streamlit==1.26.0
plotly==5.16.1
pandas==2.1.0
numpy==1.24.3
requests==2.31.0


# ============================================================
# .env.example - Environment variables template
# ============================================================
# Save as: .env.example

# Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=smart_shopper_ai
DATABASE_URL=postgresql://postgres:your_secure_password_here@localhost:5432/smart_shopper_ai

# API Configuration
API_ENV=development
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=True

# Model Configuration
MODEL_VERSION=v1.0
MODEL_TYPE=catboost

# Logging
LOG_LEVEL=INFO

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:8501


# ============================================================
# Makefile - Common commands
# ============================================================
# Save as: Makefile

.PHONY: help install train api dashboard docker-up docker-down clean

help:
	@echo "Smart Shopper AI - Available commands:"
	@echo "  make install       - Install Python dependencies"
	@echo "  make train         - Train all ML models"
	@echo "  make api           - Run FastAPI backend"
	@echo "  make dashboard     - Run Streamlit dashboard"
	@echo "  make docker-up     - Start all Docker containers"
	@echo "  make docker-down   - Stop all Docker containers"
	@echo "  make clean         - Clean temporary files"

install:
	pip install -r requirements.txt
	pip install -r requirements-streamlit.txt

train:
	python data_preprocessing.py
	python persona_clustering.py
	python purchase_prediction.py
	python incentive_recommendation.py

api:
	uvicorn api:app --host 0.0.0.0 --port 8000 --reload

dashboard:
	streamlit run streamlit_app.py

docker-up:
	docker-compose up -d

docker-down:
	docker-compose down

docker-build:
	docker-compose build

docker-logs:
	docker-compose logs -f

clean:
	find . -type d -name "__pycache__" -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	find . -type f -name "*.pyo" -delete
	find . -type f -name "*.log" -delete


# ============================================================
# init.sql - Database initialization
# ============================================================
# Save as: init.sql

-- Create database if not exists
CREATE DATABASE IF NOT EXISTS smart_shopper_ai;

-- Connect to database
\c smart_shopper_ai;

-- Create extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Grant privileges
GRANT ALL PRIVILEGES ON DATABASE smart_shopper_ai TO postgres;

-- Log
SELECT 'Database initialized successfully!' as message;
